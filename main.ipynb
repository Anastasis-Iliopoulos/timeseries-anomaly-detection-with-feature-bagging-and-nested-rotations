{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import multiprocessing_notebook_helpers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random \n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random(seed_value):\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_random(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_and_names():\n",
    "    # benchmark files checking\n",
    "    all_files=[]\n",
    "    all_files_name = []\n",
    "    for root, dirs, files in os.walk(\"./data/\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "                all_files_name.append(root.split(\"/\")[-1] + \"_\" + file.replace(\".\", \"_\"))\n",
    "    return all_files, all_files_name\n",
    "\n",
    "def get_anomaly_data_and_names():\n",
    "    all_files, all_files_name = get_files_and_names()\n",
    "    # datasets with anomalies loading\n",
    "    list_of_df = [pd.read_csv(file, \n",
    "                            sep=';', \n",
    "                            index_col='datetime', \n",
    "                            parse_dates=True) for file in all_files if 'anomaly-free' not in file]\n",
    "    list_of_names = [file for file in all_files_name if 'anomaly-free' not in file]\n",
    "    return list_of_df, list_of_names\n",
    "\n",
    "# benchmark files checking\n",
    "all_files, all_names = get_files_and_names()\n",
    "# datasets with anomalies loading\n",
    "list_of_df, list_of_names = get_anomaly_data_and_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_func(runnable_pipe_func, N_ESTIMATORS, N_CORES, list_of_df, random_seeds):\n",
    "\n",
    "    with multiprocessing.Pool(N_CORES) as pool:\n",
    "        results = [pool.apply_async(runnable_pipe_func, (f\"task_model_{str(task_ind).rjust(3,'0')}\",list_of_df, seed)) for task_ind, seed in zip(range(N_ESTIMATORS), random_seeds)]\n",
    "        \n",
    "        all_seeds = []\n",
    "        count = 0\n",
    "        for r in tqdm(results, f\"task_model_{str(count).rjust(3,'0')}\"):\n",
    "            tmp_res = r.get()\n",
    "            all_seeds.append(tmp_res)\n",
    "            count+=1\n",
    "    \n",
    "    return all_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATORS = 51\n",
    "N_CORES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[342, 3245, 4856, 6866, 3227, 7118, 6362, 7493, 6260, 7099, 9746, 5795, 7514, 8485, 1859, 4960, 680, 4831, 7679, 3022, 4618, 2698, 9141, 7000, 9082, 7857, 8371, 9497, 6504, 8686, 1052, 9523, 7695, 4409, 5850, 532, 7187, 686, 1493, 6968, 4968, 5276, 8612, 6338, 8518, 576, 2517, 2374, 7312, 2659, 8652]\n"
     ]
    }
   ],
   "source": [
    "random_seeds = np.random.choice(9999, N_ESTIMATORS, replace=False).tolist()\n",
    "print(random_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task_model_000: 100%|██████████| 51/51 [1:11:55<00:00, 84.61s/it] \n"
     ]
    }
   ],
   "source": [
    "res = driver_func(multiprocessing_notebook_helpers.run_pipeline_conv_ae, N_ESTIMATORS, N_CORES, list_of_df, random_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
