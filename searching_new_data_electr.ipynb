{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import report_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import ready_pipelines\n",
    "import tensorflow as tf\n",
    "import random \n",
    "import multiprocessing\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pn(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return({\"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\":TP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random(seed_value):\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed_value)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 14 waveforms ( features ) reported in the dataset in order are:\n",
    "1. A + IGBT-I: The current passing through the IGBT switch of phase A + in Qa1 in Fig. 2 (unit:\n",
    "A).\n",
    "2. A + ∗IGBT-I: The current passing through the IGBT switch of phase A + ∗ in Qa3 in\n",
    "Fig. 2 (unit: A).\n",
    "3. B + IGBT-I: The current passing through the IGBT switch of phase B + in Qb1 in Fig. 2 (unit:\n",
    "A).\n",
    "4. B + ∗IGBT-I: The current passing through the IGBT switch of phase B + ∗ in Qb3 in\n",
    "Fig. 2 (unit: A).\n",
    "5. C + IGBT-I: The current passing through the IGBT switch of phase C + in Qc1 in Fig. 2 (unit:\n",
    "A).\n",
    "6. C + ∗IGBT-I: The current passing through the IGBT switch of phase C + ∗ in Qc3 in\n",
    "Fig. 2 (unit: A).\n",
    "6\n",
    "M.I. Radaideh, C. Pappas and S. Cousineau / Data in Brief 43 (2022) 108473\n",
    "7. A-Flux: Magnetic flux density for phase A in transformer XA in Fig. 2 (unit: -).\n",
    "8. B-Flux: Magnetic flux density for phase B in transformer XB in Fig. 2 (unit: -).\n",
    "9. C-Flux: Magnetic flux density for phase C in transformer XC in Fig. 2 (unit: -).\n",
    "10. Mod-V: Modulator voltage (unit: V).\n",
    "11. Mod-I: Modulator current (unit: A).\n",
    "12. CB-I: Cap bank current (unit: -).\n",
    "13. CB-V: Cap bank voltage (unit: V).\n",
    "14. DV/DT: Time derivative change of the Mod-V voltage (unit: -)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dfs(X,Y):\n",
    "    original_features = [\"A_IGBT_I\", \"A_starIGBT_I\", \"B_IGBT_I\", \"B_starIGBT_I\",\n",
    "                     \"C_IGBT_I\", \"C_starIGBT_I\", \"A_Flux\", \"B_Flux\", \"C_Flux\",\n",
    "                     \"Mod_V\", \"Mod_I\", \"CB_I\", \"CB_V\", \"DV_DT\"]\n",
    "    df_list = []\n",
    "    for i_x, i_y in zip(X, Y):\n",
    "        tmp_df = pd.DataFrame(i_x, \n",
    "                            columns=original_features)\n",
    "        if i_y[1]== \"Fault\":\n",
    "            tmp_df[\"anomaly\"] = 1\n",
    "        elif i_y[1]== \"Run\":\n",
    "            tmp_df[\"anomaly\"] = 0\n",
    "        else:\n",
    "            raise ValueError(\"SOMETHING IS WRING!!!\")\n",
    "        \n",
    "        df_list.append(tmp_df)\n",
    "\n",
    "    df_all = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    df_Y = pd.DataFrame(Y, columns=[\"name\", \"status\",\"reason\"])\n",
    "    df_Y[\"anomaly\"] = df_Y.apply(lambda x: 1 if x[\"status\"] == \"Fault\" else 0, axis=1)\n",
    "    return df_all, df_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_new_data = \"./data/Real_Electronic_Signal_Data_from_Particle_Accelerator_Power_Systems\"\n",
    "system_1=\"CCL\"\n",
    "system_2=\"DTL\"\n",
    "system_3=\"RFQ\"\n",
    "system_4=\"SCL\"\n",
    "# X= np.load(f'{path_to_new_data}/{system}.npy')   #---> X array has shape: (pulses, times, features)\n",
    "# Y=np.load(f'{path_to_new_data}/{system}_labels.npy', allow_pickle=True)  #---> Y array has shape: (pulses, labels) --> labels are: index, state, type\n",
    "# time_steps=np.arange(X.shape[1]) * 400e-9    #create time axis based on the sampling rate 400 ns (for plotting purposes)\n",
    "\n",
    "# The 14 waveforms ( features ) reported in the dataset in order are:\n",
    "# original_features = [\"A_IGBT_I\", \"A_starIGBT_I\", \"B_IGBT_I\", \"B_starIGBT_I\",\n",
    "#                      \"C_IGBT_I\", \"C_starIGBT_I\", \"A_Flux\", \"B_Flux\", \"C_Flux\",\n",
    "#                      \"Mod_V\", \"Mod_I\", \"CB_I\", \"CB_V\", \"DV_DT\"]\n",
    "\n",
    "# CCL_X = np.load(f'{path_to_new_data}/{system_1}.npy')\n",
    "# CCL_Y = np.load(f'{path_to_new_data}/{system_1}_labels.npy', allow_pickle=True)\n",
    "# CCL_df, CCL_df_Y = create_dfs(CCL_X,CCL_Y)\n",
    "\n",
    "# DTL_X = np.load(f'{path_to_new_data}/{system_2}.npy')\n",
    "# DTL_Y = np.load(f'{path_to_new_data}/{system_2}_labels.npy', allow_pickle=True)\n",
    "# DTL_df, DTL_df_Y = create_dfs(DTL_X,DTL_Y)\n",
    "\n",
    "RFQ_X = np.load(f'{path_to_new_data}/{system_3}.npy')\n",
    "RFQ_Y = np.load(f'{path_to_new_data}/{system_3}_labels.npy', allow_pickle=True)\n",
    "RFQ_df, RFQ_df_Y = create_dfs(RFQ_X,RFQ_Y)\n",
    "\n",
    "RFQ_df = pd.concat([RFQ_df[:4500*20].reset_index(drop=True), RFQ_df[-4500*5:].reset_index(drop=True)], axis=0).reset_index(drop=True)\n",
    "RFQ_df_Y = pd.concat([RFQ_df_Y[:20].reset_index(drop=True), RFQ_df_Y[-5:].reset_index(drop=True)], axis=0).reset_index(drop=True)\n",
    "\n",
    "# SCL_X = np.load(f'{path_to_new_data}/{system_4}.npy')\n",
    "# SCL_Y = np.load(f'{path_to_new_data}/{system_4}_labels.npy', allow_pickle=True)\n",
    "# SCL_df, SCL_df_Y = create_dfs(SCL_X,SCL_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_func(runnable_pipe_func, SAVE_FOLDER, name_of_model, nr_subsets, nr_percentage, window_size, ucl_percentile, ucl_multiplier, family_descr, N_ESTIMATORS, N_CORES, list_of_df, random_seeds):\n",
    "\n",
    "    with multiprocessing.Pool(N_CORES) as pool:\n",
    "        results = [pool.apply_async(runnable_pipe_func, (SAVE_FOLDER, name_of_model, nr_subsets, nr_percentage, window_size, ucl_percentile, ucl_multiplier, str(family_descr), f\"task_model_{str(task_ind).rjust(3,'0')}\",list_of_df, seed)) for task_ind, seed in zip(range(N_ESTIMATORS), random_seeds)]\n",
    "        \n",
    "        all_seeds = []\n",
    "        count = 0\n",
    "        for r in tqdm(results, f\"task_model_{str(count).rjust(3,'0')}\"):\n",
    "            tmp_res = r.get()\n",
    "            all_seeds.append(tmp_res)\n",
    "            count+=1\n",
    "    \n",
    "    return all_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictd_df_Y(df, check_col):\n",
    "    data_Y_list = []\n",
    "    for i in range(0,len(df), 4500):\n",
    "        if df.iloc[i:i+4500,:][check_col].astype(bool).any():\n",
    "            data_Y_list.append((1,))\n",
    "        else:\n",
    "            data_Y_list.append((0,))\n",
    "    data_Y = pd.DataFrame(data_Y_list, columns=[check_col]).reset_index(drop=True)\n",
    "    return data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCL_df_Y\n",
    "# DTL_df_Y\n",
    "# RFQ_df_Y\n",
    "# SCL_df_Y\n",
    "list_of_df_Y = [RFQ_df_Y]\n",
    "\n",
    "# CCL_df\n",
    "# DTL_df\n",
    "# RFQ_df\n",
    "# SCL_df\n",
    "list_of_df = [RFQ_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger()\n",
    "for hdlr in log.handlers[:]:\n",
    "    log.removeHandler(hdlr)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename=f\"./logs_info.log\",\n",
    "                    format=\"CREATED_AT: %(asctime)s - MESSAGE: %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_run(N_ESTIMATORS, tmp_seed_number, SAVE_FOLDER, N_CORES, \n",
    "               name_of_model, nr_subsets, nr_percentage, window_size, \n",
    "               ucl_percentile, ucl_multiplier):\n",
    "    \n",
    "    set_random(tmp_seed_number)\n",
    "    Path(SAVE_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # log = logging.getLogger()\n",
    "    # for hdlr in log.handlers[:]:\n",
    "    #     log.removeHandler(hdlr)\n",
    "    \n",
    "    # logging.basicConfig(level=logging.INFO, filename=f\"{SAVE_FOLDER}/logs_info.log\",\n",
    "    #                     format=\"CREATED_AT: %(asctime)s - MESSAGE: %(message)s\")\n",
    "\n",
    "    log_var_tmp = ({\"N_ESTIMATORS\": N_ESTIMATORS, \"tmp_seed_number\": tmp_seed_number, \"SAVE_FOLDER\": SAVE_FOLDER, \"N_CORES\": N_CORES, \n",
    "               \"name_of_model\": name_of_model, \"nr_subsets\": nr_subsets, \"nr_percentage\": nr_percentage, \"window_size\": window_size, \n",
    "               \"ucl_percentile\": ucl_percentile, \"ucl_multiplier\": ucl_multiplier})\n",
    "    random_seeds = np.random.choice(9999, N_ESTIMATORS, replace=False).tolist()\n",
    "    logging.info(f\"'Params: general_seed: {str(tmp_seed_number)} other_seeds: [{str(random_seeds)}]' All params: [{log_var_tmp}]\")\n",
    "    \n",
    "    res = driver_func(ready_pipelines.run_pipeline_custom_electr, SAVE_FOLDER, name_of_model, nr_subsets, nr_percentage, window_size, ucl_percentile, ucl_multiplier, str(tmp_seed_number), N_ESTIMATORS, N_CORES, list_of_df, random_seeds)\n",
    "\n",
    "    time.sleep(10)\n",
    "    \n",
    "    df = report_utils.family_majority_voting(top_level_folder=SAVE_FOLDER, model_family=f\"family_conv_ae_{str(tmp_seed_number)}\")\n",
    "    df = df[[\"predicted_anomaly_majority_voting\"]]\n",
    "    df_predicted = get_predictd_df_Y(df, \"predicted_anomaly_majority_voting\")\n",
    "    df_original = list_of_df_Y[0]\n",
    "    df_original = df_original[[\"anomaly\"]]\n",
    "\n",
    "    final_df = pd.concat([df_predicted,df_original], ignore_index=False, axis=1)\n",
    "    roc_number = roc_auc_score(final_df[\"anomaly\"], final_df[\"predicted_anomaly_majority_voting\"])\n",
    "    F1 = f1_score(final_df[\"anomaly\"], final_df[\"predicted_anomaly_majority_voting\"])\n",
    "    tpfptnfn = get_pn(final_df[\"anomaly\"], final_df[\"predicted_anomaly_majority_voting\"])\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    logging.info(f\"'AUC: {roc_number} F1: {F1}\")\n",
    "    logging.info(f\"Measures: {[tpfptnfn]}\")\n",
    "    \n",
    "    # if roc_number>0.8300:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_grid_search(grid_values, **kwargs):\n",
    "    N_ESTIMATORS = kwargs.get(\"N_ESTIMATORS\", 1)\n",
    "    SAVE_FOLDER = kwargs.get(\"SAVE_FOLDER\",f\"./tmp_res_{str(N_ESTIMATORS)}\")\n",
    "    N_CORES = kwargs.get(\"N_CORES\", 1)\n",
    "    name_of_model = kwargs.get(\"name_of_model\",\"Nothing\")\n",
    "    nr_subsets = kwargs.get(\"nr_subsets\",2)\n",
    "    nr_percentage = kwargs.get(\"nr_percentage\",0.75)\n",
    "    window_size = kwargs.get(\"window_size\",None)\n",
    "    ucl_percentile = kwargs.get(\"ucl_percentile\",None)\n",
    "    ucl_multiplier = kwargs.get(\"ucl_multiplier\",None)\n",
    "    tmp_seed_number = kwargs.get(\"tmp_seed_number\",0)\n",
    "\n",
    "    \n",
    "    if (grid_values is None):\n",
    "        custom_run(N_ESTIMATORS, tmp_seed_number, SAVE_FOLDER, N_CORES, \n",
    "               name_of_model, nr_subsets, nr_percentage, window_size, \n",
    "               ucl_percentile, ucl_multiplier)\n",
    "    elif (len(grid_values)==0):\n",
    "        custom_run(N_ESTIMATORS, tmp_seed_number, SAVE_FOLDER, N_CORES, \n",
    "               name_of_model, nr_subsets, nr_percentage, window_size, \n",
    "               ucl_percentile, ucl_multiplier)\n",
    "    else:\n",
    "        grid_values_values = [value for key, value in grid_values.items()]\n",
    "        grid_values_keys = [key for key, value in grid_values.items()]\n",
    "        grid_values_combinations = list(itertools.product(*grid_values_values))\n",
    "        \n",
    "        for val_var in grid_values_combinations:\n",
    "            for grid_value_key, val_var_value in zip(grid_values_keys, val_var):\n",
    "                if \"N_ESTIMATORS\" == grid_value_key:\n",
    "                    N_ESTIMATORS = val_var_value\n",
    "                    SAVE_FOLDER = kwargs.get(\"SAVE_FOLDER\",f\"./tmp_res_{str(N_ESTIMATORS)}\")\n",
    "                elif \"tmp_seed_number\" == grid_value_key:\n",
    "                    tmp_seed_number = val_var_value\n",
    "                elif \"SAVE_FOLDER\" == grid_value_key:\n",
    "                    SAVE_FOLDER = val_var_value\n",
    "                elif \"N_CORES\" == grid_value_key:\n",
    "                    N_CORES = val_var_value\n",
    "                elif \"name_of_model\" == grid_value_key:\n",
    "                    name_of_model = val_var_value\n",
    "                elif \"nr_subsets\" == grid_value_key:\n",
    "                    nr_subsets = val_var_value\n",
    "                elif \"nr_percentage\" == grid_value_key:\n",
    "                    nr_percentage = val_var_value\n",
    "                elif \"window_size\" == grid_value_key:\n",
    "                    window_size = val_var_value\n",
    "                elif \"ucl_percentile\" == grid_value_key:\n",
    "                    ucl_percentile = val_var_value\n",
    "                elif \"ucl_multiplier\" == grid_value_key:\n",
    "                    ucl_multiplier = val_var_value\n",
    "            custom_run(N_ESTIMATORS, tmp_seed_number, SAVE_FOLDER, N_CORES, \n",
    "               name_of_model, nr_subsets, nr_percentage, window_size, \n",
    "               ucl_percentile, ucl_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task_model_000:   0%|          | 0/1 [01:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "power() takes from 2 to 3 positional arguments but 1 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\a.iliopoulos_xe\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Users\\a.iliopoulos_xe\\Desktop\\anastasisDesktop\\ensemble_diplomatiki\\new_data\\timeseries-anomaly-detection-with-feature-bagging-and-nested-rotations\\ready_pipelines.py\", line 39, in run_pipeline_custom_electr\n    tmp_model_obj.pipeline_fit(df[:4500*20].drop(['anomaly'], axis=1))\n  File \"c:\\Users\\a.iliopoulos_xe\\Desktop\\anastasisDesktop\\ensemble_diplomatiki\\new_data\\timeseries-anomaly-detection-with-feature-bagging-and-nested-rotations\\pipeline_models.py\", line 46, in pipeline_fit\n    action.fit(tmp_data, *args)\n  File \"c:\\Users\\a.iliopoulos_xe\\Desktop\\anastasisDesktop\\ensemble_diplomatiki\\new_data\\timeseries-anomaly-detection-with-feature-bagging-and-nested-rotations\\basemodels.py\", line 286, in fit\n    residuals_conv_ae = anomalyutils.get_conv_ae_residuals(X_conv_ae, predictions_conv_ae)\n  File \"c:\\Users\\a.iliopoulos_xe\\Desktop\\anastasisDesktop\\ensemble_diplomatiki\\new_data\\timeseries-anomaly-detection-with-feature-bagging-and-nested-rotations\\anomalyutils.py\", line 10, in get_conv_ae_residuals\n    return pd.Series(np.sum(np.mean(np.power(np.abs(data_true - data_predicted)), axis=1), axis=1))\nTypeError: power() takes from 2 to 3 positional arguments but 1 were given\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9220\\311629449.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mucl_percentile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0mucl_multiplier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                     name_of_model=\"CONV_AE\")\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9220\\812280515.py\u001b[0m in \u001b[0;36mcustom_grid_search\u001b[1;34m(grid_values, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m             custom_run(N_ESTIMATORS, tmp_seed_number, SAVE_FOLDER, N_CORES, \n\u001b[0;32m     51\u001b[0m                \u001b[0mname_of_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_subsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_percentage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                ucl_percentile, ucl_multiplier)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9220\\2971103479.py\u001b[0m in \u001b[0;36mcustom_run\u001b[1;34m(N_ESTIMATORS, tmp_seed_number, SAVE_FOLDER, N_CORES, name_of_model, nr_subsets, nr_percentage, window_size, ucl_percentile, ucl_multiplier)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"'Params: general_seed: {str(tmp_seed_number)} other_seeds: [{str(random_seeds)}]' All params: [{log_var_tmp}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mready_pipelines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pipeline_custom_electr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSAVE_FOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_of_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_subsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_percentage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mucl_percentile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mucl_multiplier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_seed_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_ESTIMATORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_CORES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_of_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9220\\161969170.py\u001b[0m in \u001b[0;36mdriver_func\u001b[1;34m(runnable_pipe_func, SAVE_FOLDER, name_of_model, nr_subsets, nr_percentage, window_size, ucl_percentile, ucl_multiplier, family_descr, N_ESTIMATORS, N_CORES, list_of_df, random_seeds)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"task_model_{str(count).rjust(3,'0')}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mtmp_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mall_seeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: power() takes from 2 to 3 positional arguments but 1 were given"
     ]
    }
   ],
   "source": [
    "my_list_seed = [i for i in range(50)] + [i for i in range(100,1000,50)]\n",
    "custom_grid_search({\"N_ESTIMATORS\":[1],\n",
    "                    \"tmp_seed_number\": my_list_seed,\n",
    "                    \"window_size\": [8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60],\n",
    "                    \"nr_percentage\": [0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95]},\n",
    "                    N_CORES=6,\n",
    "                    nr_subsets=2,\n",
    "                    ucl_percentile=0.999,\n",
    "                    ucl_multiplier=3/2,\n",
    "                    name_of_model=\"CONV_AE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
